{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from CustomLogisticRegression import CustomLogisticRegression as CLR\n",
    "import sklearn.discriminant_analysis as DA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def computeDiscrimination(X, prediction, sensitiveAttr):\n",
    "#     X = X.assign(prediction = prediction)\n",
    "    X = np.append(X, prediction.reshape(-1, 1), axis=1)\n",
    "    protectedGroup = X[X[:, sensitiveAttr] == 1]\n",
    "    unprotectedGroup = X[X[:, sensitiveAttr] == 0]\n",
    "    protectedCount = np.count_nonzero(protectedGroup[:, sensitiveAttr] == 1)\n",
    "    unprotectedCount = X.shape[0] - protectedCount\n",
    "    proportionOfProtected = protectedGroup[:, -1].sum() / protectedCount\n",
    "    proportionOfUnprotected = unprotectedGroup[:,-1].sum() /unprotectedCount\n",
    "    discrim = abs(proportionOfProtected - proportionOfUnprotected)\n",
    "    return discrim\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run(X, y, X_test, y_test, SA):\n",
    "#     kfold = model_selection.KFold(n_splits=5, random_state=7)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=5)\n",
    "    for i, model in enumerate(models):\n",
    "        cv_result = model_selection.cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "        model.fit(X, y)\n",
    "        prediction_test = model.predict(X_test)\n",
    "\n",
    "        acc_score_val = np.mean(cv_result)\n",
    "        acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "        discr_score = computeDiscrimination(X_test, prediction_test, SA)\n",
    "        print ('-'*40)\n",
    "        print ('val: {0}: {1}'.format(names[i], acc_score_val))\n",
    "        print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "        print('{0} discrimination: {1}'.format(names[i], discr_score))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner with the data splitting according to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdultWithSplitting(X, y, X_test, y_test, SA):\n",
    "    X_splits = np.array_split(X, 5)\n",
    "    y_splits = np.array_split(y, 5)\n",
    "    for x_split, y_split in zip(X_splits, y_splits):\n",
    "        val_amount = math.floor((1/3) * x_split.shape[0]) # 1/3 of 1 split set\n",
    "        X_val = x_split[0:val_amount]\n",
    "        y_val = y_split[0:val_amount]\n",
    "        X_train = x_split[val_amount:]\n",
    "        y_train = y_split[val_amount:]\n",
    "#         splitSize = x_split.shape[0]\n",
    "#         X_train = x_split[0:splitSize-val_amount]\n",
    "#         y_train = y_split[0:splitSize-val_amount]\n",
    "#         X_val = x_split[splitSize-val_amount:]\n",
    "#         y_val = y_split[splitSize-val_amount:]\n",
    "        for i, model in enumerate(models):\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction_val = model.predict(X_val)\n",
    "            acc_score_val = np.mean(y_val == prediction_val)\n",
    "            prediction_test = model.predict(X_test)\n",
    "            acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "            discr_score = computeDiscrimination(X_test, prediction_test, SA)\n",
    "            print ('-'*40)\n",
    "            print ('val: {0}: {1}'.format(names[i], acc_score_val))\n",
    "            print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "            print('{0} discrimination: {1}'.format(names[i], discr_score))\n",
    "        print ('-'*80)\n",
    "        print ('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runGermanWithSplitting(X, y, SA): # SA - sensitive attribute\n",
    "    X_test = np.empty_like(X[:0])\n",
    "    y_test = np.empty_like(y[:0])\n",
    "    val_acc = []\n",
    "    val_discr = []\n",
    "    X_splits = np.array_split(X, 5)\n",
    "    y_splits = np.array_split(y, 5)\n",
    "    for i, model in enumerate(models):\n",
    "        valStartPos = 0\n",
    "        valEndPos = 0\n",
    "        for x_split, y_split in zip(X_splits, y_splits):\n",
    "            valEndPos += math.floor(0.2 * x_split.shape[0]) # 20% of 1 split set\n",
    "            train_amount = math.floor(0.5 * x_split.shape[0]) # 50% of 1 split set (round)\n",
    "            X_val = x_split[valStartPos:valEndPos] # 20% of the split\n",
    "            y_val = y_split[valStartPos:valEndPos]\n",
    "            # the remaining 80% of the split\n",
    "            remaining_X_subset = np.array(x_split[:valStartPos])\n",
    "            remaining_X_subset = np.append(remaining_X_subset, x_split[valEndPos:], axis=0)\n",
    "            remaining_y_subset = np.array(y_split[:valStartPos])\n",
    "            remaining_y_subset = np.append(remaining_y_subset, y_split[valEndPos:], axis=0)\n",
    "            X_train = remaining_X_subset[0:train_amount] # 50% of 1 split set (test set)\n",
    "            y_train = remaining_y_subset[0:train_amount]\n",
    "            X_test = np.append(X_test, remaining_X_subset[train_amount:], axis=0)\n",
    "            y_test = np.append(y_test, remaining_y_subset[train_amount:], axis=0)\n",
    "            model.fit(X_train, y_train)        \n",
    "            prediction_val = model.predict(X_val)\n",
    "            acc_score_val = np.mean(y_val == prediction_val)\n",
    "            val_acc.append(acc_score_val)\n",
    "            discr_score_val = computeDiscrimination(X_val, prediction_val, SA)\n",
    "            val_discr.append(discr_score_val)\n",
    "            # slide the start position of the validation set            \n",
    "            valStartPos += math.floor(0.2 * x_split.shape[0]) # 20% of 1 split set\n",
    "        # calculate the mean of accuracy and discrimination based on validation dataset    \n",
    "        val_acc_score = np.mean(val_acc)\n",
    "        val_discr_acc_score = np.mean(val_discr)\n",
    "        \n",
    "        prediction_test = model.predict(X_test)\n",
    "        acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "        discr_score_test = computeDiscrimination(X_test, prediction_test, SA)\n",
    "        delta = acc_score_test - discr_score_test\n",
    "        print ('-'*40)\n",
    "        print ('val: {0}: {1}'.format(names[i], val_acc_score))\n",
    "        print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "        print('{0} discrimination val: {1}'.format(names[i], val_discr_acc_score))\n",
    "        print('{0} discrimination test: {1}'.format(names[i], discr_score_test))\n",
    "        print('delta: {0}'.format(delta))\n",
    "        print ('-'*100)\n",
    "        print ('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "names = ['LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10)',\n",
    "         'LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10)',\n",
    "         'LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=1500)',\n",
    "         'Regularized logistic regression(): '\n",
    "#          'Linear Discriminant Analysis',\n",
    "#          'Quadratic Discriminant Analysis',\n",
    "#          'Random Forest',\n",
    "#          'Neural Network',\n",
    "#          'Gaussian NB',\n",
    "#          'Bernoulli NB',\n",
    "#          'Complement NB',\n",
    "#          'Multinomial NB',\n",
    "#          'Random Forest',\n",
    "#          'K Neighbors Classifier',\n",
    "#          'SVM',\n",
    "#          'LinearSVC'\n",
    "]\n",
    "\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=700, penalty='none'))\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=1400, penalty='none'))\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=2100, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=100, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=500, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=1500, penalty='none'))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=1000, C=1e10))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=2000, C=1e10))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=3000, C=1e10))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=1000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=3000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=5000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=700, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=1400, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=2100, penalty='none'))\n",
    "models.append(CLR(0.1, 100))\n",
    "models.append(CLR(0.1, 500))\n",
    "models.append(CLR(0.1, 1500))\n",
    "models.append(CLR(0.01, 100))\n",
    "models.append(CLR(0.01, 500))\n",
    "models.append(CLR(0.01, 1500))\n",
    "models.append(CLR(0.001, 100))\n",
    "models.append(CLR(0.001, 500))\n",
    "models.append(CLR(0.001, 1500))\n",
    "models.append(CLR(0.0001, 100))\n",
    "models.append(CLR(0.0001, 500))\n",
    "models.append(CLR(0.0001, 1500))\n",
    "models.append(LogisticRegression())\n",
    "# models.append(DA.LinearDiscriminantAnalysis())\n",
    "# models.append(DA.QuadraticDiscriminantAnalysis())\n",
    "# models.append(RandomForestClassifier(n_estimators=100))\n",
    "# models.append(MLPClassifier())\n",
    "# models.append(GaussianNB())\n",
    "# models.append(BernoulliNB())\n",
    "# models.append(ComplementNB())\n",
    "# models.append(MultinomialNB())\n",
    "# models.append(DecisionTreeClassifier())\n",
    "# models.append(KNeighborsClassifier(n_neighbors=50))\n",
    "# models.append(SVC())\n",
    "# models.append(LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_adult, pct = load_adult('datasets/adult/adult.data')\n",
    "X_adult = df_adult.iloc[:, :-1]\n",
    "y_adult = df_adult.iloc[:, -1]\n",
    "print('percentage of corrupt rows: {0:.1f}%'.format((1-pct)*100))\n",
    "\n",
    "df_adult_test, pct = load_adult('datasets/adult/adult.test')\n",
    "X_adult_test = df_adult_test.iloc[:, :-1]\n",
    "y_adult_test = df_adult_test.iloc[:, -1]\n",
    "print('percentage of corrupt rows in testing: {0:.1f}%'.format((1-pct)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_adult['sex'] = X_adult['sex'].map({'Female': 1, 'Male': 0}).astype(int)\n",
    "# X_adult_test['sex'] = X_adult_test['sex'].map({'Female': 1, 'Male': 0}).astype(int)\n",
    "\n",
    "X_adult, X_adult_test = encode_adult(X_adult, X_adult_test)\n",
    "\n",
    "X_adult_all = X_adult.append(X_adult_test)\n",
    "X_adult_all_expand = pd.get_dummies(X_adult_all)\n",
    "\n",
    "# X_expand, X_expand_test = encode_adult(X_expand, X_expand_test)\n",
    "X_adult_expand = X_adult_all_expand[0:X_adult.shape[0]]\n",
    "X_adult_expand_test = X_adult_all_expand[X_adult.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run(X_expand, y_adult, X_expand_test, y_adult_test, 'sex')\n",
    "runAdultWithSplitting(X_adult_expand, y_adult, X_adult_expand_test, y_adult_test, 'sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load german dataset\n",
    "df_german = load_german('datasets/german/german.data')\n",
    "X_german = df_german.iloc[:, :-1]\n",
    "y_german = df_german.iloc[:, -1]\n",
    "\n",
    "# One hot encoder\n",
    "X_german_encoded = pd.get_dummies(X_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_german_encoded, y_german, test_size=0.3, shuffle=False)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_german, y_german, test_size=0.3, random_state=42)\n",
    "# X_german, X_german_test = encode_german(X_german, X_german_test)\n",
    "X_german_all_expand = encode_german_all(X_german_encoded)\n",
    "\n",
    "# X_expand, X_expand_test = encode_adult(X_expand, X_expand_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.655\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.7\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10) discrimination val: 0.37403285638579753\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10) discrimination test: 0.029550827423167836\n",
      "delta: 0.6704491725768321\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.6549999999999999\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.7\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10) discrimination val: 0.37403285638579764\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10) discrimination test: 0.029550827423167836\n",
      "delta: 0.6704491725768321\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.6549999999999998\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.7\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10) discrimination val: 0.37403285638579764\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10) discrimination test: 0.029550827423167836\n",
      "delta: 0.6704491725768321\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10): 0.6487499999999999\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10): 0.6833333333333333\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10) discrimination val: 0.38855122090416205\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10): 0.645\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10): 0.6833333333333333\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10) discrimination val: 0.3972622396151808\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10): 0.6425000000000001\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10): 0.6833333333333333\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10) discrimination val: 0.40306958542252663\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10): 0.6407142857142857\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10): 0.6833333333333333\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10) discrimination val: 0.4057128880658293\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10): 0.639375\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10): 0.6833333333333333\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10) discrimination val: 0.4076953650483063\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10): 0.6383333333333334\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10): 0.6833333333333333\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10) discrimination val: 0.4092372915902328\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10): 0.639\n",
      "test: LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10): 0.68\n",
      "LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10) discrimination val: 0.40058864294158414\n",
      "LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10) discrimination test: 0.08156028368794332\n",
      "delta: 0.5984397163120567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10): 0.64\n",
      "test: LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10): 0.6833333333333333\n",
      "LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10) discrimination val: 0.39400387635681755\n",
      "LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5982269503546099\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10): 0.6408333333333333\n",
      "test: LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10): 0.68\n",
      "LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10) discrimination val: 0.388516570869512\n",
      "LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10) discrimination test: 0.08156028368794332\n",
      "delta: 0.5984397163120567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.6415384615384615\n",
      "test: LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.6766666666666666\n",
      "LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10) discrimination val: 0.38278598821585247\n",
      "LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10) discrimination test: 0.08510638297872342\n",
      "delta: 0.5915602836879432\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.6421428571428571\n",
      "test: LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.68\n",
      "LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10) discrimination val: 0.37860666095960216\n",
      "LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10) discrimination test: 0.08156028368794332\n",
      "delta: 0.5984397163120567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.6423333333333333\n",
      "test: LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.68\n",
      "LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10) discrimination val: 0.37488293723587846\n",
      "LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10) discrimination test: 0.08156028368794332\n",
      "delta: 0.5984397163120567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.1, max_itr=100): 0.640625\n",
      "test: Custom Logistic Regression(lr=0.1, max_itr=100): 0.6833333333333333\n",
      "Custom Logistic Regression(lr=0.1, max_itr=100) discrimination val: 0.3636100750071338\n",
      "Custom Logistic Regression(lr=0.1, max_itr=100) discrimination test: 0.17966903073286056\n",
      "delta: 0.5036643026004728\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.1, max_itr=500): 0.6391176470588236\n",
      "test: Custom Logistic Regression(lr=0.1, max_itr=500): 0.6833333333333333\n",
      "Custom Logistic Regression(lr=0.1, max_itr=500) discrimination val: 0.36021408685768547\n",
      "Custom Logistic Regression(lr=0.1, max_itr=500) discrimination test: 0.047281323877068515\n",
      "delta: 0.6360520094562648\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.1, max_itr=1500): 0.6383333333333334\n",
      "test: Custom Logistic Regression(lr=0.1, max_itr=1500): 0.67\n",
      "Custom Logistic Regression(lr=0.1, max_itr=1500) discrimination val: 0.35986008633067457\n",
      "Custom Logistic Regression(lr=0.1, max_itr=1500) discrimination test: 0.099290780141844\n",
      "delta: 0.570709219858156\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.01, max_itr=100): 0.6431578947368422\n",
      "test: Custom Logistic Regression(lr=0.01, max_itr=100): 0.7066666666666667\n",
      "Custom Logistic Regression(lr=0.01, max_itr=100) discrimination val: 0.3579061080609068\n",
      "Custom Logistic Regression(lr=0.01, max_itr=100) discrimination test: 0.13120567375886527\n",
      "delta: 0.5754609929078014\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.01, max_itr=500): 0.6447499999999999\n",
      "test: Custom Logistic Regression(lr=0.01, max_itr=500): 0.7033333333333334\n",
      "Custom Logistic Regression(lr=0.01, max_itr=500) discrimination val: 0.35649708532061475\n",
      "Custom Logistic Regression(lr=0.01, max_itr=500) discrimination test: 0.047281323877068515\n",
      "delta: 0.6560520094562649\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.01, max_itr=1500): 0.6461904761904761\n",
      "test: Custom Logistic Regression(lr=0.01, max_itr=1500): 0.68\n",
      "Custom Logistic Regression(lr=0.01, max_itr=1500) discrimination val: 0.3577302577302578\n",
      "Custom Logistic Regression(lr=0.01, max_itr=1500) discrimination test: 0.03664302600472813\n",
      "delta: 0.6433569739952719\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.001, max_itr=100): 0.6520454545454544\n",
      "test: Custom Logistic Regression(lr=0.001, max_itr=100): 0.72\n",
      "Custom Logistic Regression(lr=0.001, max_itr=100) discrimination val: 0.3465533406709878\n",
      "Custom Logistic Regression(lr=0.001, max_itr=100) discrimination test: 0.23758865248226957\n",
      "delta: 0.4824113475177304\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.001, max_itr=500): 0.6554347826086957\n",
      "test: Custom Logistic Regression(lr=0.001, max_itr=500): 0.7133333333333334\n",
      "Custom Logistic Regression(lr=0.001, max_itr=500) discrimination val: 0.34443304213125175\n",
      "Custom Logistic Regression(lr=0.001, max_itr=500) discrimination test: 0.13829787234042556\n",
      "delta: 0.5750354609929078\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.001, max_itr=1500): 0.6585416666666667\n",
      "test: Custom Logistic Regression(lr=0.001, max_itr=1500): 0.7033333333333334\n",
      "Custom Logistic Regression(lr=0.001, max_itr=1500) discrimination val: 0.3435603590015355\n",
      "Custom Logistic Regression(lr=0.001, max_itr=1500) discrimination test: 0.12056737588652489\n",
      "delta: 0.5827659574468085\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.0001, max_itr=100): 0.6607999999999999\n",
      "test: Custom Logistic Regression(lr=0.0001, max_itr=100): 0.6633333333333333\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=100) discrimination val: 0.32981794464147407\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=100) discrimination test: 0.0\n",
      "delta: 0.6633333333333333\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.0001, max_itr=500): 0.6628846153846154\n",
      "test: Custom Logistic Regression(lr=0.0001, max_itr=500): 0.6733333333333333\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=500) discrimination val: 0.31713263907834044\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=500) discrimination test: 0.02009456264775411\n",
      "delta: 0.6532387706855792\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Custom Logistic Regression(lr=0.0001, max_itr=1500): 0.6664814814814815\n",
      "test: Custom Logistic Regression(lr=0.0001, max_itr=1500): 0.73\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=1500) discrimination val: 0.31073577348087156\n",
      "Custom Logistic Regression(lr=0.0001, max_itr=1500) discrimination test: 0.2127659574468086\n",
      "delta: 0.5172340425531914\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: Regularized logistic regression(): : 0.66875\n",
      "test: Regularized logistic regression(): : 0.7166666666666667\n",
      "Regularized logistic regression():  discrimination val: 0.31078809902339316\n",
      "Regularized logistic regression():  discrimination test: 0.14184397163120566\n",
      "delta: 0.574822695035461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# run(X_train, y_train, X_test, y_test, 'Age')\n",
    "runGermanWithSplitting(X_german_all_expand, y_german, 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most similar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "names = ['CLR(0.01, 100)',\n",
    "]\n",
    "\n",
    "models.append(CLR(0.01, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAdultWithSplitting(X_adult_expand, y_adult, X_adult_expand_test, y_adult_test, 'sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runGermanWithSplitting(X_german_all_expand, y_german, 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
