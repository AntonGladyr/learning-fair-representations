{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from CustomLogisticRegression import CustomLogisticRegression as CLR\n",
    "import sklearn.discriminant_analysis as DA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def computeDiscrimination(X_test, prediction, sensitiveAttr):\n",
    "    X_test = X_test.assign(prediction = prediction)\n",
    "    protectedGroup = X_test[X_test[sensitiveAttr] == 1]\n",
    "    unprotectedGroup = X_test[X_test[sensitiveAttr] == 0]\n",
    "    proportionOfProtected = protectedGroup['prediction'].sum() / protectedGroup[sensitiveAttr].count()\n",
    "    proportionOfUnprotected = unprotectedGroup['prediction'].sum() / protectedGroup[sensitiveAttr].count()\n",
    "    discrim = abs(proportionOfProtected - proportionOfUnprotected)\n",
    "    return discrim\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run(X, y, X_test, y_test, SA):\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "#     kfold = model_selection.StratifiedKFold(n_splits=5)\n",
    "    for i, model in enumerate(models):\n",
    "        cv_result = model_selection.cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "        model.fit(X, y)\n",
    "        prediction_test = model.predict(X_test)\n",
    "\n",
    "        acc_score_val = np.mean(cv_result)\n",
    "        acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "        discr_score = computeDiscrimination(X_test, prediction_test, SA)\n",
    "        print ('-'*40)\n",
    "        print ('val: {0}: {1}'.format(names[i], acc_score_val))\n",
    "        print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "        print('{0} discrimination: {1}'.format(names[i], discr_score))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner with the data splitting according to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def runAdultWithSplitting(X, y, X_test, y_test, SA):\n",
    "#     X_splits = np.array_split(X, 5)\n",
    "#     y_splits = np.array_split(y, 5)\n",
    "#     for x_split, y_split in zip(X_splits, y_splits):\n",
    "#         val_amount = math.floor((1/3) * x_split.shape[0]) # 1/3 of 1 split set\n",
    "#         X_val = x_split[0:val_amount]\n",
    "#         y_val = y_split[0:val_amount]\n",
    "#         X_train = x_split[val_amount:]\n",
    "#         y_train = y_split[val_amount:]\n",
    "# #         splitSize = x_split.shape[0]\n",
    "# #         X_train = x_split[0:splitSize-val_amount]\n",
    "# #         y_train = y_split[0:splitSize-val_amount]\n",
    "# #         X_val = x_split[splitSize-val_amount:]\n",
    "# #         y_val = y_split[splitSize-val_amount:]\n",
    "#         for i, model in enumerate(models):\n",
    "#             model.fit(X_train, y_train)\n",
    "#             prediction_val = model.predict(X_val)\n",
    "#             acc_score_val = np.mean(y_val == prediction_val)\n",
    "#             prediction_test = model.predict(X_test)\n",
    "#             acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "#             discr_score = computeDiscrimination(X_test, prediction_test, SA)\n",
    "#             print ('-'*40)\n",
    "#             print ('val: {0}: {1}'.format(names[i], acc_score_val))\n",
    "#             print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "#             print('{0} discrimination: {1}'.format(names[i], discr_score))\n",
    "#         print ('-'*80)\n",
    "#         print ('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdultWithSplitting(X, y, X_test, y_test, SA):\n",
    "    X_splits = np.array_split(X, 5)\n",
    "    y_splits = np.array_split(y, 5)\n",
    "    for i, model in enumerate(models):\n",
    "        acc_list = []\n",
    "        disc_list = []\n",
    "        for x_split, y_split in zip(X_splits, y_splits):\n",
    "            val_amount = math.floor((1/3) * x_split.shape[0]) # 1/3 of 1 split set\n",
    "            X_val = x_split[0:val_amount]\n",
    "            y_val = y_split[0:val_amount]\n",
    "            X_train = x_split[val_amount:]\n",
    "            y_train = y_split[val_amount:]\n",
    "    #         splitSize = x_split.shape[0]\n",
    "    #         X_train = x_split[0:splitSize-val_amount]\n",
    "    #         y_train = y_split[0:splitSize-val_amount]\n",
    "    #         X_val = x_split[splitSize-val_amount:]\n",
    "    #         y_val = y_split[splitSize-val_amount:]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction_val = model.predict(X_val)\n",
    "            acc_score_val = np.mean(y_val == prediction_val)\n",
    "            acc_list.append(acc_score_val)\n",
    "#         prediction_test = model.predict(X_test)\n",
    "#         acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "            discr_score = computeDiscrimination(X_val, prediction_val, SA)\n",
    "            disc_list.append(discr_score)\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        prediction_test = model.predict(X_test)\n",
    "        acc_score_test = np.mean(y_test == prediction_test)\n",
    "        print ('-'*40)\n",
    "        print ('val: {0}: {1}'.format(names[i], np.mean(acc_list)))\n",
    "        print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "        print('{0} discrimination: {1}'.format(names[i], np.mean(disc_list)))\n",
    "        print ('-'*80)\n",
    "        print ('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runGermanWithSplitting(X, y, SA):\n",
    "    X_splits = np.array_split(X, 5)\n",
    "    y_splits = np.array_split(y, 5)\n",
    "    for x_split, y_split in zip(X_splits, y_splits):\n",
    "        train_amount = math.floor(0.5 * x_split.shape[0]) # 50% of 1 split set (round)\n",
    "        X_train = x_split[0:train_amount]\n",
    "        y_train = y_split[0:train_amount]\n",
    "        val_amount = math.floor(0.2 * x_split.shape[0]) # 20% of 1 split set\n",
    "        X_val = x_split[train_amount:train_amount+val_amount]\n",
    "        y_val = y_split[train_amount:train_amount+val_amount]\n",
    "        X_test = x_split[train_amount+val_amount:] # 30% of 1 split set\n",
    "        y_test = y_split[train_amount+val_amount:]\n",
    "        for i, model in enumerate(models):\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction_val = model.predict(X_val)\n",
    "            acc_score_val = np.mean(y_val == prediction_val)\n",
    "            prediction_test = model.predict(X_test)\n",
    "#             acc_score_test = accuracy_score(y_test, prediction_test)\n",
    "            acc_score_test = 1 - (np.mean(abs(y_test - prediction_test)))\n",
    "            discr_score = computeDiscrimination(X_test, prediction_test, SA)\n",
    "            print ('-'*40)\n",
    "            print ('val: {0}: {1}'.format(names[i], acc_score_val))\n",
    "            print ('test: {0}: {1}'.format(names[i], acc_score_test))\n",
    "            print('{0} discrimination: {1}'.format(names[i], discr_score))\n",
    "        print ('-'*80)\n",
    "        print ('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "names = ['LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10)',\n",
    "         'LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10)',\n",
    "         'LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10)',\n",
    "         'LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10)',\n",
    "         'LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=3000, penalty=none, C=1e10)',\n",
    "         'LR(solver=sag, fit_intercept=False, max_iter=5000, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=700, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=1400, penalty=none, C=1e10)',\n",
    "         'LR(solver=saga, fit_intercept=False, max_iter=2100, penalty=none, C=1e10)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.1, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.01, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.001, max_itr=1500)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=100)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=500)',\n",
    "         'Custom Logistic Regression(lr=0.0001, max_itr=1500)',\n",
    "#          'Linear Discriminant Analysis',\n",
    "#          'Quadratic Discriminant Analysis',\n",
    "#          'Random Forest',\n",
    "#          'Neural Network',\n",
    "#          'Gaussian NB',\n",
    "#          'Bernoulli NB',\n",
    "#          'Complement NB',\n",
    "#          'Multinomial NB',\n",
    "#          'Random Forest',\n",
    "#          'K Neighbors Classifier',\n",
    "#          'SVM',\n",
    "#          'LinearSVC'\n",
    "]\n",
    "\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=700, penalty='none'))\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=1400, penalty='none'))\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=2100, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=100, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=500, penalty='none'))\n",
    "models.append(LogisticRegression(solver='newton-cg', fit_intercept=False, max_iter=1500, penalty='none'))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=1000, C=1e10))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=2000, C=1e10))\n",
    "models.append(LogisticRegression(solver='liblinear', fit_intercept=False, max_iter=3000, C=1e10))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=1000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=3000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='sag', fit_intercept=False, max_iter=5000, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=700, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=1400, penalty='none'))\n",
    "models.append(LogisticRegression(solver='saga', fit_intercept=False, max_iter=2100, penalty='none'))\n",
    "models.append(CLR(0.1, 100))\n",
    "models.append(CLR(0.1, 500))\n",
    "models.append(CLR(0.1, 1500))\n",
    "models.append(CLR(0.01, 100))\n",
    "models.append(CLR(0.01, 500))\n",
    "models.append(CLR(0.01, 1500))\n",
    "models.append(CLR(0.001, 100))\n",
    "models.append(CLR(0.001, 500))\n",
    "models.append(CLR(0.001, 1500))\n",
    "models.append(CLR(0.0001, 100))\n",
    "models.append(CLR(0.0001, 500))\n",
    "models.append(CLR(0.0001, 1500))\n",
    "# models.append(DA.LinearDiscriminantAnalysis())\n",
    "# models.append(DA.QuadraticDiscriminantAnalysis())\n",
    "# models.append(RandomForestClassifier(n_estimators=100))\n",
    "# models.append(MLPClassifier())\n",
    "# models.append(GaussianNB())\n",
    "# models.append(BernoulliNB())\n",
    "# models.append(ComplementNB())\n",
    "# models.append(MultinomialNB())\n",
    "# models.append(DecisionTreeClassifier())\n",
    "# models.append(KNeighborsClassifier(n_neighbors=50))\n",
    "# models.append(SVC())\n",
    "# models.append(LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of corrupt rows in training: 7.4%\n",
      "percentage of corrupt rows in testing: 7.5%\n"
     ]
    }
   ],
   "source": [
    "df_adult, pct = load_adult('datasets/adult/adult.data')\n",
    "X_adult = df_adult.iloc[:, :-1]\n",
    "y_adult = df_adult.iloc[:, -1]\n",
    "print('percentage of corrupt rows in training: {0:.1f}%'.format((1-pct)*100))\n",
    "\n",
    "df_adult_test, pct = load_adult('datasets/adult/adult.test')\n",
    "X_adult_test = df_adult_test.iloc[:, :-1]\n",
    "y_adult_test = df_adult_test.iloc[:, -1]\n",
    "print('percentage of corrupt rows in testing: {0:.1f}%'.format((1-pct)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_adult, X_adult_test = encode_adult(X_adult, X_adult_test)\n",
    "\n",
    "X_adult_all = X_adult.append(X_adult_test)\n",
    "X_adult_all_expand = pd.get_dummies(X_adult_all)\n",
    "\n",
    "# X_expand, X_expand_test = encode_adult(X_expand, X_expand_test)\n",
    "X_adult_expand = X_adult_all_expand[0:X_adult.shape[0]]\n",
    "X_adult_expand_test = X_adult_all_expand[X_adult.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# encoders = {\"workclass\": preprocessing.LabelEncoder(), \n",
    "#             \"education\": preprocessing.LabelEncoder(), \n",
    "#             \"marital-status\": preprocessing.LabelEncoder(), \n",
    "#             \"occupation\": preprocessing.LabelEncoder(), \n",
    "#             \"relationship\": preprocessing.LabelEncoder(), \n",
    "#             \"race\": preprocessing.LabelEncoder(), \n",
    "#             \"sex\": preprocessing.LabelEncoder(), \n",
    "#             \"native-country\": preprocessing.LabelEncoder()}\n",
    "\n",
    "# X_encoded = encode(X_adult, encoders)\n",
    "# X_encoded_test = encode(X_adult_test, encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=700, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=1400, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=lbfgs, fit_intercept=False, max_iter=2100, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=100, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=500, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10): 0.8292875750536229\n",
      "test: LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=newton-cg, fit_intercept=False, max_iter=1500, penalty=none, C=1e10) discrimination: 0.4612302495137398\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10): 0.8293870280620765\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10): 0.8341965471447543\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=1000, C=1e10) discrimination: 0.4615482145375872\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10): 0.8293870280620765\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10): 0.8341965471447543\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=2000, C=1e10) discrimination: 0.4615482145375872\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------------\n",
      "val: LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10): 0.8293870280620765\n",
      "test: LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10): 0.8341965471447543\n",
      "LR(solver=liblinear, fit_intercept=False, max_iter=3000, C=1e10) discrimination: 0.4615482145375872\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "val: LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10): 0.8293870280620765\n",
      "test: LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10): 0.8341965471447543\n",
      "LR(solver=sag, fit_intercept=False, max_iter=1000, penalty=none, C=1e10) discrimination: 0.4615482145375872\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-469084ad509a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run(X_expand, y_adult, X_expand_test, y_adult_test, 'sex')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunAdultWithSplitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_adult_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_adult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_adult_expand_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_adult_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# run(X_adult_expand, y_adult, X_adult_expand_test, y_adult_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f7693f963044>\u001b[0m in \u001b[0;36mrunAdultWithSplitting\u001b[0;34m(X, y, X_test, y_test, SA)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#         X_val = x_split[splitSize-val_amount:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#         y_val = y_split[splitSize-val_amount:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprediction_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0macc_score_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1606\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    331\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run(X_expand, y_adult, X_expand_test, y_adult_test, 'sex')\n",
    "runAdultWithSplitting(X_adult_expand, y_adult, X_adult_expand_test, y_adult_test, 'sex')\n",
    "# run(X_adult_expand, y_adult, X_adult_expand_test, y_adult_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load german dataset\n",
    "df_german = load_german('datasets/german/german.data')\n",
    "X_german = df_german.iloc[:, :-1]\n",
    "y_german = df_german.iloc[:, -1]\n",
    "\n",
    "X_german, X_german_test, y_german, y_german_test = train_test_split(X_german, y_german, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expanding (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_german, X_german_test = encode_german(X_german, X_german_test)\n",
    "\n",
    "X_german_all = X_german.append(X_german_test)\n",
    "X_german_all_expand = pd.get_dummies(X_german_all)\n",
    "\n",
    "# X_expand, X_expand_test = encode_adult(X_expand, X_expand_test)\n",
    "X_german_expand = X_german_all_expand[0:X_german.shape[0]]\n",
    "X_german_expand_test = X_german_all_expand[X_german.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_german_expand = encode_german_all(X_german)\n",
    "X_german_all_expand = pd.get_dummies(X_german_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_german_encoded, y_german, test_size=0.3, shuffle=False)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_german, y_german, test_size=0.3, random_state=42)\n",
    "X_german_all_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run(X_train, y_train, X_test, y_test, 'Age')\n",
    "runGermanWithSplitting(X_german_all_expand, y_german, 12);\n",
    "# run(X_german_expand, y_german, X_german_expand_test, y_german_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most similar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "names = ['LR(solver=lbfgs, fit_intercept=False, max_iter=10000, penalty=none, C=1e10)',\n",
    "]\n",
    "\n",
    "models.append(LogisticRegression(solver='lbfgs', fit_intercept=False, max_iter=10000, penalty='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runAdultWithSplitting(X_expand, y_adult, X_expand_test, y_adult_test, 'sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runGermanWithSplitting(X_german_encoded, y_german, 'Age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_german_encoded, y_german, test_size=0.3, shuffle=False)\n",
    "run(X_german_expand, y_german, X_german_expand_test, y_german_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
